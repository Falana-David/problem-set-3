# LingoGPTConnector/realtime_voice.py
#
# Realtime Voice WebSocket client for LingoGPTConnector
# - Uses Config.get_realtime_config() for endpoint/deployment/version/ws_path
# - Supports KEY (api-key) and TOKEN (bearer + projectId) auth
# - Provides a RealtimeConnection with helpers to:
#     - session_update()
#     - input_audio_append(pcm_bytes)
#     - input_audio_commit()
#     - response_create()
#     - iter_events()  (raw events)
#     - iter_audio_deltas() (decoded audio chunks only)

from __future__ import annotations

import aiohttp
import base64
import json
import ssl
from dataclasses import dataclass, field
from typing import Any, AsyncIterator, Dict, Optional

from LingoGPTConnector.config import Config


@dataclass
class RealtimeSessionParams:
    """
    Session-level parameters applied via `session.update`.
    """
    voice: str = "alloy"
    input_audio_format: str = "pcm16"
    output_audio_format: str = "pcm16"

    # Server VAD vs manual (push-to-talk)
    # - {"type": "server_vad"} => server auto-detects turns
    # - None => caller commits and triggers responses manually
    turn_detection: Optional[Dict[str, Any]] = field(default_factory=lambda: {"type": "server_vad"})

    # Optional: enable transcription of user audio (depends on your deployment support)
    # Example: {"model": "<deployment-or-model-id>"}
    input_audio_transcription: Optional[Dict[str, Any]] = None

    # Any additional session fields you want to pass through
    extra_session: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RealtimeResponseParams:
    """
    Response-level parameters applied via `response.create`.
    """
    modalities: list[str] = field(default_factory=lambda: ["text", "audio"])
    instructions: Optional[str] = None

    # Any additional response fields you want to pass through
    extra_response: Dict[str, Any] = field(default_factory=dict)


class RealtimeVoiceClient:
    """
    Factory that opens a realtime WebSocket connection using Config.get_realtime_config().
    """

    def __init__(self, config: Config, ssl_verify: bool = True):
        self.config = config
        self.ssl_verify = ssl_verify

        if not ssl_verify:
            ctx = ssl.create_default_context()
            ctx.check_hostname = False
            ctx.verify_mode = ssl.CERT_NONE
            self._ssl_context = ctx
        else:
            self._ssl_context = None

    def _to_ws_base_url(self, https_url: str) -> str:
        """
        Convert https://... to wss://... and ensure it ends with a trailing slash
        because aiohttp.ClientSession(base_url=...) expects a base.
        """
        if https_url.startswith("https://"):
            ws = "wss://" + https_url[len("https://") :]
        elif https_url.startswith("http://"):
            ws = "ws://" + https_url[len("http://") :]
        else:
            ws = https_url

        return ws.rstrip("/") + "/"

    def _build_headers(self, cfg: dict) -> Dict[str, str]:
        """
        Build auth headers based on KEY vs TOKEN mode.
        """
        headers: Dict[str, str] = {}

        if cfg["resource_flag"] == "KEY":
            # Many Azure OpenAI websocket endpoints accept `api-key`.
            # If your gateway expects different headers, update here.
            api_key = cfg.get("api_key")
            if not api_key:
                raise ValueError("Realtime: api_key missing for resource_flag=KEY")
            headers["api-key"] = api_key
        else:
            token = self.config.get_openai_token()
            headers["Authorization"] = f"Bearer {token}"

            project_id = cfg.get("project_id")
            if project_id:
                headers["projectId"] = str(project_id)

        # Optional gateway header (if you added it to config)
        if cfg.get("x_upstream_env"):
            headers["x-upstream-env"] = str(cfg["x_upstream_env"])

        return headers

    async def connect(
        self,
        *,
        session_params: Optional[RealtimeSessionParams] = None,
        response_params: Optional[RealtimeResponseParams] = None,
    ) -> "RealtimeConnection":
        """
        Opens the websocket and sends an initial `session.update`.
        """
        cfg = self.config.get_realtime_config()

        api_url = cfg.get("api_url")
        if not api_url:
            raise ValueError("Realtime: api_url missing in config.")

        deployment = cfg.get("deployment")
        if not deployment:
            raise ValueError(
                "Realtime: deployment missing in config. "
                "Set LINGO_REALTIME_DEPLOYMENT."
            )

        api_version = cfg.get("api_version")
        if not api_version:
            raise ValueError("Realtime: api_version missing in config.")

        ws_path = cfg.get("ws_path", "openai/realtime")
        ws_path = ws_path.lstrip("/")

        ws_base_url = self._to_ws_base_url(api_url)
        headers = self._build_headers(cfg)

        params = {
            "deployment": deployment,
            "api-version": api_version,
        }

        http_session = aiohttp.ClientSession(base_url=ws_base_url)
        ws = await http_session.ws_connect(
            ws_path,
            headers=headers,
            params=params,
            ssl=self._ssl_context,
            heartbeat=30,
        )

        conn = RealtimeConnection(
            http_session=http_session,
            ws=ws,
            session_params=session_params or RealtimeSessionParams(),
            response_params=response_params or RealtimeResponseParams(),
        )

        # Apply session config before caller starts sending audio
        await conn.session_update()
        return conn


class RealtimeConnection:
    """
    Represents a live realtime websocket session.
    """

    def __init__(
        self,
        *,
        http_session: aiohttp.ClientSession,
        ws: aiohttp.ClientWebSocketResponse,
        session_params: RealtimeSessionParams,
        response_params: RealtimeResponseParams,
    ):
        self.http_session = http_session
        self.ws = ws
        self.session_params = session_params
        self.response_params = response_params

    async def close(self) -> None:
        try:
            await self.ws.close()
        finally:
            await self.http_session.close()

    async def send_event(self, event: Dict[str, Any]) -> None:
        await self.ws.send_str(json.dumps(event))

    async def session_update(self) -> None:
        """
        Send `session.update` with formats/voice/turn_detection/etc.
        """
        session_obj: Dict[str, Any] = {
            "turn_detection": self.session_params.turn_detection,
            "voice": self.session_params.voice,
            "input_audio_format": self.session_params.input_audio_format,
            "output_audio_format": self.session_params.output_audio_format,
        }

        if self.session_params.input_audio_transcription:
            session_obj["input_audio_transcription"] = self.session_params.input_audio_transcription

        if self.session_params.extra_session:
            session_obj.update(self.session_params.extra_session)

        await self.send_event({"type": "session.update", "session": session_obj})

    async def input_audio_append(self, pcm_bytes: bytes) -> None:
        """
        Append raw PCM bytes to the server-side audio buffer.
        Must match the `input_audio_format` you declared (e.g. pcm16).
        """
        await self.send_event(
            {
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(pcm_bytes).decode("utf-8"),
            }
        )

    async def input_audio_commit(self) -> None:
        """
        Commit the audio buffer into a user message (push-to-talk mode).
        """
        await self.send_event({"type": "input_audio_buffer.commit"})

    async def response_create(self, *, override: Optional[RealtimeResponseParams] = None) -> None:
        """
        Trigger the model response generation.
        """
        rp = override or self.response_params

        resp_obj: Dict[str, Any] = {"modalities": rp.modalities}

        if rp.instructions:
            resp_obj["instructions"] = rp.instructions

        if rp.extra_response:
            resp_obj.update(rp.extra_response)

        await self.send_event({"type": "response.create", "response": resp_obj})

    async def iter_events(self) -> AsyncIterator[Dict[str, Any]]:
        """
        Yield parsed JSON events from the websocket until it closes.
        """
        while True:
            msg = await self.ws.receive()

            if msg.type == aiohttp.WSMsgType.CLOSED:
                break

            if msg.type == aiohttp.WSMsgType.ERROR:
                raise RuntimeError(f"WebSocket error: {msg}")

            if msg.type != aiohttp.WSMsgType.TEXT:
                continue

            yield json.loads(msg.data)

    async def iter_audio_deltas(self) -> AsyncIterator[bytes]:
        """
        Convenience iterator that yields decoded bytes from `response.audio.delta`
        until `response.audio.done` is received.
        """
        async for event in self.iter_events():
            t = event.get("type")

            if t == "response.audio.delta":
                yield base64.b64decode(event["delta"])

            elif t == "response.audio.done":
                return

            elif t == "error":
                raise RuntimeError(event)
