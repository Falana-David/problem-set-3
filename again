import asyncio
import base64
import io
import json
import wave
from datetime import datetime

import numpy as np
import streamlit as st

from LingoGPTConnector.config import Config
from LingoGPTConnector.realtime_voice import (
    RealtimeVoiceClient,
    RealtimeSessionParams,
    RealtimeResponseParams,
)


# ----------------------------
# Streamlit async runner
# ----------------------------
def run_async(coro):
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None

    if loop and loop.is_running():
        new_loop = asyncio.new_event_loop()
        try:
            return new_loop.run_until_complete(coro)
        finally:
            new_loop.close()

    return asyncio.run(coro)


# ----------------------------
# Audio helpers
# ----------------------------
def wav_bytes_to_int16_mono(wav_bytes: bytes) -> tuple[np.ndarray, int]:
    """Decode WAV -> (int16 mono, sample_rate)."""
    with wave.open(io.BytesIO(wav_bytes), "rb") as wf:
        ch = wf.getnchannels()
        sw = wf.getsampwidth()
        sr = wf.getframerate()
        frames = wf.readframes(wf.getnframes())

    if sw != 2:
        raise ValueError(f"Expected 16-bit PCM WAV. Got sampwidth={sw}.")

    x = np.frombuffer(frames, dtype=np.int16)

    if ch == 1:
        mono = x
    elif ch == 2:
        mono = x.reshape(-1, 2).mean(axis=1).astype(np.int16)
    else:
        raise ValueError(f"Unsupported channels={ch}. Expected 1 or 2.")

    return mono, sr


def resample_linear_int16(x: np.ndarray, src_sr: int, dst_sr: int) -> np.ndarray:
    """Simple linear resampling (fine for debugging)."""
    if src_sr == dst_sr:
        return x

    x_f = x.astype(np.float32)
    src_n = len(x_f)
    dst_n = int(round(src_n * (dst_sr / src_sr)))

    src_idx = np.arange(src_n, dtype=np.float32)
    dst_idx = np.linspace(0, src_n - 1, dst_n, dtype=np.float32)
    y = np.interp(dst_idx, src_idx, x_f)
    return np.clip(np.round(y), -32768, 32767).astype(np.int16)


def pcm16_to_wav_bytes(pcm16: bytes, sr: int) -> bytes:
    out = io.BytesIO()
    with wave.open(out, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sr)
        wf.writeframes(pcm16)
    return out.getvalue()


def safe_event_summary(evt: dict) -> dict:
    """Log event type + lengths, not raw payloads."""
    t = evt.get("type")
    s = {"type": t}

    if t == "response.audio.delta":
        s["audio_b64_len"] = len(evt.get("delta", ""))

    if t == "response.text.delta":
        s["text_len"] = len(evt.get("delta", ""))

    if t == "error":
        s["error"] = evt.get("error", evt)

    return s


# ----------------------------
# Realtime mic roundtrip
# ----------------------------
async def realtime_mic_roundtrip(
    pcm16_mono: bytes,
    *,
    input_sr: int = 24000,
    output_sr: int = 24000,
    voice: str = "alloy",
    instructions: str | None = None,
    chunk_ms: int = 100,
    max_events: int = 600,
) -> dict:
    """
    - Connect using Config.get_realtime_config()
    - session.update includes voice + pcm16 formats + sampling rates
    - Append audio chunks -> commit
    - response.create modalities=["audio"]
    - Collect response.audio.delta until response.audio.done
    - Keep reading beyond response.done until audio.done (some servers do that)
    """
    cfg = Config()
    rtc = RealtimeVoiceClient(cfg, ssl_verify=True)

    session_params = RealtimeSessionParams(
        voice=voice,
        input_audio_format="pcm16",
        output_audio_format="pcm16",
        turn_detection=None,  # push-to-talk
        extra_session={
            "input_audio_sampling_rate": input_sr,
            "output_audio_sampling_rate": output_sr,
        },
    )

    # Force audio-only to eliminate text-only replies
    response_params = RealtimeResponseParams(
        modalities=["audio"],
        instructions=instructions,
    )

    conn = await rtc.connect(session_params=session_params, response_params=response_params)

    logs = []
    assistant_audio = bytearray()
    saw_audio_done = False
    saw_response_done = False

    bytes_per_ms = int(input_sr * 2 / 1000)  # mono PCM16
    chunk_bytes = max(640, bytes_per_ms * chunk_ms)

    try:
        # Send audio
        for i in range(0, len(pcm16_mono), chunk_bytes):
            await conn.input_audio_append(pcm16_mono[i : i + chunk_bytes])

        await conn.input_audio_commit()

        # IMPORTANT: response.create must include "response" object (your wrapper does)
        await conn.response_create()

        # Read events
        count = 0
        async for evt in conn.iter_events():
            count += 1
            logs.append(safe_event_summary(evt))

            t = evt.get("type")

            if t == "response.audio.delta":
                assistant_audio.extend(base64.b64decode(evt["delta"]))

            elif t == "response.audio.done":
                saw_audio_done = True
                # If we already saw response.done, we can stop.
                if saw_response_done:
                    break

            elif t == "response.done":
                saw_response_done = True
                # Do NOT stop unless audio is done.
                if saw_audio_done:
                    break

            elif t == "error":
                raise RuntimeError(evt)

            if count >= max_events:
                logs.append({"type": "debug.stop", "reason": "max_events_reached"})
                break

        return {
            "assistant_pcm16": bytes(assistant_audio),
            "logs": logs,
            "saw_audio_done": saw_audio_done,
            "saw_response_done": saw_response_done,
        }

    finally:
        await conn.close()


# ----------------------------
# UI
# ----------------------------
st.set_page_config(page_title="Realtime Mic Test", layout="centered")
st.title("GPT Realtime Mic Test (WebSocket Audio)")

with st.expander("Settings", expanded=True):
    voice = st.selectbox("Voice", ["alloy", "verse", "aria", "sage", "ember", "coral"], index=0)
    instructions = st.text_area("Instructions", value="Answer briefly.", height=80)
    input_sr = st.selectbox("Input sample rate to send", [24000, 16000], index=0)
    output_sr = st.selectbox("Output WAV sample rate", [24000, 16000, 48000], index=0)
    chunk_ms = st.slider("Chunk size (ms)", 20, 200, 100, 10)

st.caption(
    "Uses ONLY Config.get_realtime_config() and Config.get_openai_token(). "
    "No extra env vars. If audio is supported, you will see response.audio.delta."
)

audio_file = st.audio_input("Record (mic)", sample_rate=16000)

if audio_file is not None:
    user_wav = audio_file.read()
    st.audio(user_wav, format="audio/wav")

    if st.button("Send to Realtime"):
        try:
            mono, sr = wav_bytes_to_int16_mono(user_wav)
            mono_rs = resample_linear_int16(mono, sr, input_sr)
            pcm_bytes = mono_rs.tobytes()

            with st.spinner("Connecting + streaming mic audio..."):
                result = run_async(
                    realtime_mic_roundtrip(
                        pcm_bytes,
                        input_sr=input_sr,
                        output_sr=output_sr,
                        voice=voice,
                        instructions=instructions.strip() or None,
                        chunk_ms=chunk_ms,
                    )
                )

            pcm = result["assistant_pcm16"]
            st.write(f"PCM bytes received: {len(pcm)}")
            st.write(f"saw_audio_done: {result['saw_audio_done']} | saw_response_done: {result['saw_response_done']}")

            if len(pcm) == 0:
                st.error("No response.audio.delta received (assistant audio empty).")
            else:
                wav = pcm16_to_wav_bytes(pcm, output_sr)
                st.success("Audio received âœ…")
                st.audio(wav, format="audio/wav")

                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    "Download WAV",
                    data=wav,
                    file_name=f"assistant_reply_{ts}.wav",
                    mime="audio/wav",
                )

            st.subheader("Event log (safe)")
            st.code(json.dumps(result["logs"], indent=2)[:20000])

        except Exception as e:
            st.error(f"Error: {e}")
